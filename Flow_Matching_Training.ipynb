{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhnyfsUF2Qju3CQx44uApb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aparey/Guided-flow-match/blob/main/Flow_Matching_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0Pxdul7tG_Y"
      },
      "outputs": [],
      "source": [
        "####Connect Google Drive####\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####Importing Libraries####\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab_Notebooks/CS_682/')"
      ],
      "metadata": {
        "id": "AG_Jpk2JtPNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdiffeq\n",
        "!pip install torchmetrics\n",
        "!pip install torchviz\n",
        "!pip install torch-fidelity"
      ],
      "metadata": {
        "id": "k2lmX4_gtVus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torchmetrics.functional.multimodal import clip_score\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "import pickle\n",
        "from functools import partial\n",
        "import torchviz\n",
        "from torchviz import make_dot\n",
        "import PIL\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tqdm\n",
        "from torchdiffeq import odeint\n",
        "import os\n",
        "\n",
        "from caption_generation import CIFAR10WithCaptions\n",
        "from unet_attn import UNet\n",
        "from text_encoding import reshape_text"
      ],
      "metadata": {
        "id": "v88jz2UetYAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Helper Functions####\n",
        "def convert(loss_vals):\n",
        "  new_loss= []\n",
        "  for i in loss_vals:\n",
        "    new_loss.append(i)\n",
        "  return new_loss"
      ],
      "metadata": {
        "id": "RKFvFTKPtbc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Load the dataset####\n",
        "def uncond_dataset():\n",
        "  transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "  train_dataset = torchvision.datasets.CIFAR10(root='./drive/MyDrive/CS 682/CS682 Project/uncond_dataset/train/', train=True,\n",
        "                                          download=True, transform=transform)\n",
        "  test_dataset = torchvision.datasets.CIFAR10(root='./drive/MyDrive/CS 682/CS682 Project/uncond_dataset/train/', train=False,\n",
        "                                          download=True, transform=transform)\n",
        "\n",
        "  class Custom_CIFAR_train(torch.utils.data.Dataset):\n",
        "    def __init__(self, train_dataset):\n",
        "      self.target_imgs = train_dataset\n",
        "    def __getitem__(self, idx):\n",
        "      return self.target_imgs[idx][0]\n",
        "    def __len__(self):\n",
        "      return len(train_dataset)\n",
        "\n",
        "  flow_train_dataset = Custom_CIFAR_train(train_dataset)\n",
        "  flow_test_dataset = Custom_CIFAR_train(test_dataset)\n",
        "\n",
        "  return flow_train_dataset, flow_test_dataset"
      ],
      "metadata": {
        "id": "0s3W2FkAtif4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cond_dataset():\n",
        "  with open('/content/drive/MyDrive/Colab_Notebooks/CS_682/Data/CAPTIONED_CIFAR_TRAIN.pkl', 'rb') as file:\n",
        "    flow_train_dataset = pickle.load(file)\n",
        "  with open('/content/drive/MyDrive/Colab_Notebooks/CS_682/Data/CAPTIONED_CIFAR_TEST.pkl', 'rb') as file:\n",
        "    flow_test_dataset = pickle.load(file)\n",
        "  return flow_train_dataset, flow_test_dataset"
      ],
      "metadata": {
        "id": "D4sPSm7Ptnx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(conditional_gen=False):\n",
        "  if conditional_gen:\n",
        "    return cond_dataset()\n",
        "  else:\n",
        "    return uncond_dataset()"
      ],
      "metadata": {
        "id": "GIpoonDGtqQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Sampling####\n",
        "def sample_from_dataset(dataset, conditional_dataset=False):\n",
        "  idx = torch.randint(0, len(dataset))\n",
        "  if conditional_dataset:\n",
        "    c_img, label, caption = dataset[idx]\n",
        "  else:\n",
        "    g_img, c_img = dataset[idx]\n",
        "  plt.imshow(g_img.permute(1,2,0))\n",
        "  plt.imshow(c_img.permute(1,2,0))"
      ],
      "metadata": {
        "id": "fAizSPXUtyX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Train-Val Split####\n",
        "def split_train_dataset(flow_train_dataset, train_frac):\n",
        "  flow_train_dataset, flow_val_dataset = torch.utils.data.random_split(flow_train_dataset, [train_frac, 1-train_frac])\n",
        "  return flow_train_dataset, flow_val_dataset"
      ],
      "metadata": {
        "id": "yZvulRe1t4jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Create DataLoaders####\n",
        "def gen_loaders(dataset, batch_size):\n",
        "  return torch.utils.data.DataLoader(dataset, batch_size=batch_size, pin_memory=True,num_workers = 6)"
      ],
      "metadata": {
        "id": "j3EfeMOZt_2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Model Initialisation####\n",
        "def model_init(convnet = True, conditional_gen=False):\n",
        "  if conditional_gen:\n",
        "    return UNet(conditional_gen = conditional_gen)\n",
        "  else:\n",
        "    return UNet(conditional_gen = conditional_gen)"
      ],
      "metadata": {
        "id": "sqVgcFnCuFNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Masking Function####\n",
        "def masking_tokens(tokens, pad_token=0):\n",
        "  p = torch.rand(1)\n",
        "  mask = torch.zeros(tokens.size())\n",
        "  if p<0.1:\n",
        "    tokens = tokens * mask\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "iHG8akNDuOCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Loss Function####\n",
        "def loss(vf_flow, x_1, t, reshape_text, tokens = None, conditional_gen = False):\n",
        "\n",
        "  x_0 = torch.rand(x_1.shape).to(\"cuda\")\n",
        "\n",
        "  xt = t[:, None, None, None]*x_1 + (1-t[:,None, None, None])*x_0\n",
        "  xt = xt.cuda()\n",
        "\n",
        "  true_flow = x_1 - x_0\n",
        "  if conditional_gen:\n",
        "    tokens = reshape_text(tokens)\n",
        "    tokens = masking_tokens(tokens).to('cuda')\n",
        "  if conditional_gen:\n",
        "     predicted_flow, _ = vf_flow(t, (xt, tokens))\n",
        "  else:\n",
        "    predicted_flow  = vf_flow(t, xt)\n",
        "  flow_objective_loss = torch.sum((predicted_flow - true_flow)**2, axis=(1,2,3))\n",
        "  avg_obj_loss = torch.mean(flow_objective_loss)\n",
        "  return avg_obj_loss"
      ],
      "metadata": {
        "id": "6wi7ya8XuWg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Training Loop####\n",
        "def train_one_epoch(min_delta, patience, epochs,\n",
        "                    flow_train_dataset,\n",
        "                    lr, batch_size, reshape_text,\n",
        "                    convnet = True, conditional_gen=False,\n",
        "                    epoch_print = 1, infer_num = 0, epoch_save = 250, final_infer_num = 3):\n",
        "\n",
        "    loss_vals = []\n",
        "    infer_imgs = []\n",
        "    num_iter = -1\n",
        "    flow_train_loader = gen_loaders(flow_train_dataset, batch_size)\n",
        "    vf_flow = model_init(convnet, conditional_gen)\n",
        "    vf_flow.to('cuda')\n",
        "    optimizer = torch.optim.Adam(vf_flow.parameters(), lr = lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      if (epoch % epoch_save == 0 and epoch != 0):\n",
        "        plot_loss(loss_vals)\n",
        "        torch.save(vf_flow, f'/content/drive/MyDrive/Colab_Notebooks/CS_682/Models/Conditional/Intermediate/conditional_unet_honey_ham_epoch_{epoch}.pth')\n",
        "      if (epoch % epoch_print == 0 and epoch!=0):\n",
        "        print(f'Epoch: {epoch} \\nLoss: {loss_vals[-1]}')\n",
        "        print('-------------------')\n",
        "      for i, data in enumerate(flow_train_loader):\n",
        "        num_iter+=1\n",
        "        stop = True\n",
        "        t = torch.rand(len(data[0])).to('cuda')\n",
        "\n",
        "        if conditional_gen:\n",
        "          x_1, labels, captions, x_0 = data\n",
        "          loss_val = loss(vf_flow, x_1.to('cuda'), t, reshape_text.to('cuda'), captions, conditional_gen=True)\n",
        "        else:\n",
        "          x_0, x_1 = data\n",
        "          loss_val = loss(vf_flow, x_1.to('cuda'), t, reshape_text.to('cuda'))\n",
        "\n",
        "        loss_vals.append(loss_val.item())\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss_val.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    final_images = []\n",
        "    torch.save(vf_flow, '/content/drive/MyDrive/Colab_Notebooks/CS_682/Models/Conditional/Final/conditional_unet_honey_ham_final.pth')\n",
        "    for infers in range(final_infer_num):\n",
        "          idx = torch.randint(0, len(flow_train_dataset), (1,)).item()\n",
        "          if conditional_gen:\n",
        "            img = inference(vf_flow, caption = flow_train_dataset[idx][2], reshape_text=reshape_text, conditional_gen=True).to('cpu').permute(1,2,0)\n",
        "          else:\n",
        "            img = inference(vf_flow, conditional_gen=False).to('cpu').permute(1,2,0)\n",
        "          plt.imshow(img)\n",
        "          plt.show()\n",
        "          final_images.append(img)\n",
        "    plot_loss(loss_vals)\n",
        "    return loss_vals, infer_imgs, final_images, vf_flow"
      ],
      "metadata": {
        "id": "b5HfXpp3uc1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Model Vizualization####\n",
        "def model_viz_print(model):\n",
        "  print(model)\n",
        "\n",
        "def model_viz_graph(model, conditional_gen=False):\n",
        "  if conditional_gen:\n",
        "    x = torch.rand(2,4,32,32)\n",
        "    t = torch.FloatTensor([0.0,1.0])\n",
        "  else:\n",
        "    x = torch.rand(2,3,32,32)\n",
        "    t = torch.FloatTensor([0.0,1.0])\n",
        "  make_dot(model(t,x))"
      ],
      "metadata": {
        "id": "wGnuiXy6un4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####ODE Solver for Inference####\n",
        "def inference(model, caption=None, reshape_text=None, conditional_gen=False):\n",
        "  x_0 = torch.rand(1,3,32,32).to('cuda')\n",
        "  if conditional_gen:\n",
        "    tokens = reshape_text([caption]).to('cuda')\n",
        "\n",
        " # t = torch.linspace(0.0,1.0,10) # To observe the change in the image\n",
        "  t = torch.tensor([0.0, 1.0]).to('cuda')\n",
        "\n",
        "  with torch.no_grad():\n",
        "      if conditional_gen:\n",
        "        x_1, _ = odeint(model, (x_0, tokens), t, method='dopri5', atol=1e-5, rtol=1e-5)\n",
        "      else:\n",
        "        x_1 = odeint(model, x_0, t, method='dopri5', atol=1e-5, rtol=1e-5)\n",
        "  return x_1[-1,0]"
      ],
      "metadata": {
        "id": "AC5W1eKDuuHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Loss Curve Plot####\n",
        "def plot_loss(loss_vals):\n",
        "  plt.xlabel('#iterations')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.plot(list(range(len(loss_vals))), convert(loss_vals))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "IE-yvQnKu2pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Unconditional Flow Matching####\n",
        "flow_train_dataset, flow_test_dataset = load_dataset(False)\n",
        "flow_train_dataset, flow_val_dataset = split_train_dataset(flow_train_dataset, 0.98)\n",
        "ds_size = 30"
      ],
      "metadata": {
        "id": "LSTLPMEDu-HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import math\n",
        "imgs = []\n",
        "\n",
        "for img in range(ds_size):\n",
        "  imgs.append(flow_train_dataset[img][1].permute(1,2,0))\n",
        "\n",
        "  ncols = 10\n",
        "  nrows = math.ceil(ds_size / ncols)\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(10., 4.))\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(nrows, ncols),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, imgs):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(im)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GyCXUpfPvFh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_delta = 0\n",
        "patience = 10\n",
        "epochs = 2000\n",
        "lr = 1e-4\n",
        "batch_size = 128\n",
        "epoch_print = 1\n",
        "epoch_save = 6\n",
        "infer_num = 0\n",
        "final_infer_num = 10\n",
        "conditional_gen = False\n",
        "convnet = True\n",
        "\n",
        "\n",
        "print(f'train for <{epochs}> epochs')\n",
        "print(f'learning rate is <{lr}>')\n",
        "print(f'batch size is <{batch_size}>')\n",
        "print(f'conditional generation is set to <{conditional_gen}>')\n",
        "print(f'print loss every <{epoch_print}> epochs')\n",
        "print(f'generate <{infer_num}> images every <{epoch_print}> epochs')\n",
        "print(f'save intermediate models every <{epoch_save}> epochs')\n",
        "print(f'generate <{final_infer_num}> images after training')"
      ],
      "metadata": {
        "id": "zv5kcS4ZvHw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_vals, infer_imgs,final_infers, model = train_one_epoch(min_delta, patience, epochs,\n",
        "                                                            flow_train_dataset,\n",
        "                                                            lr, batch_size, reshape_text,\n",
        "                                                            convnet=convnet, conditional_gen=conditional_gen,\n",
        "                                                            epoch_print=epoch_print, epoch_save=epoch_save, infer_num = infer_num,\n",
        "                                                            final_infer_num=final_infer_num)"
      ],
      "metadata": {
        "id": "4PrGN20JvKSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import set_loglevel\n",
        "import math\n",
        "\n",
        "plot_loss(loss_vals)\n",
        "\n",
        "total_infers = len(infer_imgs)\n",
        "grid_cols = 10\n",
        "grid_rows = math.ceil(total_infers / grid_cols)\n",
        "\n",
        "plt.set_loglevel(\"critical\")\n",
        "fig = plt.figure(figsize=(grid_cols, grid_rows))\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(grid_rows, grid_cols),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, infer_imgs):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(im)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "final_infer_num = 3\n",
        "grid_rows = math.ceil(final_infer_num / grid_cols)\n",
        "fig = plt.figure(figsize=(grid_cols, grid_rows))\n",
        "\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(grid_rows, grid_cols),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, final_infers):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(im)\n",
        "\n",
        "plt.show()\n",
        "plt.set_loglevel(\"warning\")"
      ],
      "metadata": {
        "id": "Y3mdkbIcvNSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####Conditional Flow Matching####\n",
        "flow_train_dataset, flow_test_dataset = load_dataset(True)\n",
        "flow_train_dataset, flow_val_dataset = split_train_dataset(flow_train_dataset, 0.98)\n",
        "ds_size = 30"
      ],
      "metadata": {
        "id": "n8v-F-3ZvTFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "imgs = []\n",
        "\n",
        "for img in range(ds_size):\n",
        "  imgs.append(flow_train_dataset[img][0].permute(1,2,0))\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(10., 4.))\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(3, 10),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, imgs):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(im)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m79EIZGFvXp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(ds_size):\n",
        "  print(flow_train_dataset[i][2])"
      ],
      "metadata": {
        "id": "g2LydtL_vaH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_delta = 0\n",
        "patience = 10\n",
        "epochs = 2500\n",
        "lr = 3e-4\n",
        "batch_size = 128\n",
        "epoch_print = 1\n",
        "epoch_save = 6\n",
        "infer_num = 0\n",
        "final_infer_num = 10\n",
        "conditional_gen = True\n",
        "convnet = True\n",
        "\n",
        "\n",
        "print(f'train for <{epochs}> epochs')\n",
        "print(f'learning rate is <{lr}>')\n",
        "print(f'batch size is <{batch_size}>')\n",
        "print(f'conditional generation is set to <{conditional_gen}>')\n",
        "print(f'print loss every <{epoch_print}> epochs')\n",
        "print(f'generate <{infer_num}> images every <{epoch_print}> epochs')\n",
        "print(f'save intermediate models every <{epoch_save}> epochs')\n",
        "print(f'generate <{final_infer_num}> images after training')"
      ],
      "metadata": {
        "id": "PPaWFOPPvc0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_vals, infer_imgs,final_infers, model = train_one_epoch(min_delta, patience, epochs,\n",
        "                                                            flow_train_dataset,\n",
        "                                                            lr, batch_size, reshape_text,\n",
        "                                                            convnet=convnet, conditional_gen=conditional_gen,\n",
        "                                                            epoch_print=epoch_print, epoch_save=epoch_save, infer_num = infer_num,\n",
        "                                                            final_infer_num=final_infer_num)"
      ],
      "metadata": {
        "id": "IaVm9ygKvvi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import set_loglevel\n",
        "import math\n",
        "\n",
        "plot_loss(loss_vals)\n",
        "\n",
        "total_infers = len(infer_imgs)\n",
        "grid_cols = 10\n",
        "grid_rows = math.ceil(total_infers / grid_cols)\n",
        "\n",
        "plt.set_loglevel(\"critical\")\n",
        "fig = plt.figure(figsize=(grid_cols, grid_rows))\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(grid_rows, grid_cols),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, infer_imgs):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(im)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "final_infer_num = 3\n",
        "grid_rows = math.ceil(final_infer_num / grid_cols)\n",
        "fig = plt.figure(figsize=(grid_cols, grid_rows))\n",
        "\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(grid_rows, grid_cols),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, final_infers):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(im)\n",
        "\n",
        "plt.show()\n",
        "plt.set_loglevel(\"warning\")"
      ],
      "metadata": {
        "id": "VoIVi01LvzOu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}